Линейный классификатор принимает решение о классе объекта, основываясь на [линейной](https://ru.wikipedia.org/wiki/%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F) предсказывающей функции, совмещающей набор весовых коэффициентов с вектором признаков.

Если входной вектор признаков для классификатора – вектор $\vec {x}$, тогда результатом будет

$$y=f(\vec {w} \cdot \vec {x}) = f ( \sum_{j} w_{j} x_{j})$$

где $\vec {w}$ – вектор весов, а $f$ – та самая линейная функция, преобразующая произведение двух векторов в желаемый результат (в нашем случае — ответ на вопрос, болен ли человек диабетом 2-го типа).

Сначала наша задача состоит в том, чтобы настроить вектор весов $\vec {w}$ на примере обучающей выборки. Так алгоритм "запомнит", какой вклад каждый из признаков, к примеру, возраст или индекс массы тела, вносит в вероятность обнаружения диабета.

Зачастую f – [пороговая функция](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%BE%D1%80%D0%BE%D0%B3%D0%BE%D0%B2%D0%B0%D1%8F_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F), которая относит $ \vec {w} \cdot \vec {x}$ выше некоторого порога к первому классу, а остальные значения — ко второму.

Для нашей задачи классификации можно представить линейный классификатор как разбиение входных данных с высокой размерностью с помощью гиперплоскости: все объекты с одной стороны гиперплоскости классифицируются как наличие диабета, остальные же классифицируются как его отсутствие (см. иллюстрацию в предыдущем задании, где показаны примеры с размерностью пространства данных n = 2 и n = 3).

Потерями (**loss**) называют ошибку в предсказанных значениях. Цель — минимизировать ошибку и получить наиболее точный результат.

Существует [несколько способов](https://en.wikipedia.org/wiki/Loss_functions_for_classification) вычислить потери. Мы будем использовать функции `log_loss` и `sigmoid_loss`.

Логарифмическая функция потерь:

$$L(M) = \log_2(1 + e^{-M})$$

Сигмоидная функция потерь (она же сигмоида):

$$L(M) = 2(1 + e^{M})^{-1}$$

### Задание

Реализуйте логарифмическую (`log_loss`) и сигмоидную (`sigmoid_loss`) функции потерь. Функция потерь должна принимать на вход вектор *отступов* (величина, характеризующая, насколько близко классифицированный объект находится к границе двух классов, более подробно см. в следующем задании) и возвращать пару из вектора значений функции потерь и вектора её производных. Например, если бы
мы решили использовать степенную функцию потерь:

$$L(M) = {M}^{n}$$

    def power_loss(M, n=5):
        return M ** n, n * (M ** (n - 1))

Функции потерь определены в `loss_functions.py`.

<div class="hint">
Производная логарифмической функции потерь:
$$L(M) = \dfrac{-1}{\log_2(1 + e^{-M})}$$
</div>

<div class="hint">
Производная сигмоидной функции потерь:
$$L(M) = \dfrac{-2 * e^{M}}{{(1 + e^{M})}^{2}}$$
</div>

Визуализация работы функций потерь будет представлена в следующем задании, когда мы сконструируем вектор весов $\vec{w}$.
