#Вступление

Индейцы племени пима проживают в центральной и южной части штата Аризона. По не до конца изученным на данный момент причинам
индейцы пима имеют критический риск заболевания сахарным диабетом (2 типа). Была выдвинута гипотеза, что повышенная распространенность диабета среди коренных американцев – это результат взаимодействия генетической предрасположенности, резкого изменения диеты за последние столетия (переход от традиционных сельскохозяйственных культур к обработанным пищевым продуктам), а также снижения физической активности. В этом задании предлагается применить [линейный
классификатор](http://www.machinelearning.ru/wiki/index.php?title=%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80) для оценки по данным анамнеза, может ли человек быть болен диабетом 2 типа.

![Pima](pima.png)
Мы выбрали данный алгоритм исходя из следующих соображений:
 - Не так просто рассчитать расстояние между объектами из выборки — различные типы медицинских данных в анамнезе каждого из пациентов осложняют построение метрики.
 - Затруднительным выглядит и построение предикатов — неясно, какие комбинации признаков влияют на заболевание.
 - Неясно, из какого [вероятностного пространства](https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%82%D0%B2%D0%BE) объекты.

Рассмотренный в данном уроке *алгоритм градиентного спуска* не требует вычисления расстояния, построения предикатов или же чтобы объекты были из одного вероятностного пространства.
#Описание .csv
В файле `pima-indians-diabetes.csv` ([источник](https://www.kaggle.com/uciml/pima-indians-diabetes-database)) находятся медицинские данные представителей племени пима.
Последняя колонка каждой строки — индикатор наличия сахарного диабета (2 типа). Значения остальных колонок указаны в заголовке
файла.
#  Задание
При реализации линейного классификатора предполагается, что объекты лежат в некотором `n`-мерном пространстве и мы можем провести `(n-1)`-мерную плоскость, чтобы отделить один класс от другого (здесь `n` - число признаков).

![hyperplane](hyperplane.png)

Для начала необходимо прочитать данные из файла и привести их к необходимому для использования алгоритма формату.

Реализуйте функцию `read_data`, которая принимает путь к файлу с данными и возвращает пару из двух массивов NumPy.

- Первый элемент пары — матрица признаков `X`, в первой колонке которой находится константный признак `-1` (это псевдопризнак, к которому мы будем обращаться в дальнейшем для использования каждого объекта как вектора в скалярном произведении), а в остальных –
признаки из файла с данными. Признаки будут стандартизированы ([eng.](https://www.kdnuggets.com/2020/04/data-transformation-standardization-normalization.html)), т.н. значение каждого из них будет выравнено вокруг среднего для всех объектов, отступая от него не боле, чем на стандартное отклонение:
$$ x_{stand} = \dfrac {x - mean(x)} {standard \ deviation (x)}$$
- Второй элемент пары — вектор `y`, в котором `-1` означает наличие диабета, а `1` — его отсутствие. Этот вектор подвергается нормализации данных. Процедура необходима для того, чтобы сравнивать знак произведения векторов с предполагаемым классом.

<div class="hint">
Во время выполнения задания могут быть полезны следующие функции: <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.mean.html">numpy.ndarray.mean</a>, <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.std.html">numpy.mdarray.std</a>, <a href="https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html">np.concatenate</a>. 
</div>